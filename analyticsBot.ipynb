{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7r5q1Y+yTLxxd09WLxeF5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youssefsalah224/Algorithm_main/blob/main/analyticsBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q google-analytics-data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US6JsmkMjiIV",
        "outputId": "5007411a-3336-481c-867d-9b7f8177c05e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/153.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.1/153.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag, ne_chunk\n",
        "from google.analytics.data_v1beta import BetaAnalyticsDataClient\n",
        "from google.analytics.data_v1beta.types import (\n",
        "    DateRange,\n",
        "    Dimension,\n",
        "    Metric,\n",
        "    MetricType,\n",
        "    RunReportRequest,\n",
        ")\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "id": "KGiStq1hcgpG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c381942-4531-40ec-f90c-9fe2cc34c4a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "id": "8VuFUZSZjB7X",
        "outputId": "d2743826-f575-40d1-95b6-8702fc68a58f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter your quieres     (u need to inter the matrix right)   fitch the totalUsers and the browser\n",
            "totalUsers\n",
            "2 analytics rows found\n",
            "Dimension header name: browser\n",
            "Metric header name: totalUsers (TYPE_INTEGER)\n",
            "Report result:\n",
            "\n",
            "Row 0\n",
            "browser: Chrome\n",
            "totalUsers: 1\n",
            "\n",
            "Row 1\n",
            "browser: Safari\n",
            "totalUsers: 1\n",
            "dimension_headers {\n",
            "  name: \"browser\"\n",
            "}\n",
            "metric_headers {\n",
            "  name: \"totalUsers\"\n",
            "  type_: TYPE_INTEGER\n",
            "}\n",
            "rows {\n",
            "  dimension_values {\n",
            "    value: \"Chrome\"\n",
            "  }\n",
            "  metric_values {\n",
            "    value: \"1\"\n",
            "  }\n",
            "}\n",
            "rows {\n",
            "  dimension_values {\n",
            "    value: \"Safari\"\n",
            "  }\n",
            "  metric_values {\n",
            "    value: \"1\"\n",
            "  }\n",
            "}\n",
            "row_count: 2\n",
            "metadata {\n",
            "  currency_code: \"EGP\"\n",
            "  time_zone: \"Africa/Cairo\"\n",
            "}\n",
            "kind: \"analyticsData#runReport\"\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'json_object = json.dumps(data, indent=4)\\n\\n# Writing to sample.json\\nwith open(\"sample.json\", \"w\") as outfile:\\n\\toutfile.write(data)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'service_key.json'\n",
        "\n",
        "\n",
        "def extract_metrics(input_text):\n",
        "    words = nltk.word_tokenize(input_text)\n",
        "    metric_mapping = {\n",
        "        \"addToCarts\",\n",
        "        \"sessions\",\n",
        "        \"totalUsers\",\n",
        "        \"totalUsers\",\n",
        "        \"itemsPurchased\",\n",
        "        \"totalAdRevenue\"\n",
        "    }\n",
        "    for word in words:\n",
        "      if word in metric_mapping:\n",
        "        matrics=word\n",
        "        print(matrics)\n",
        "    return matrics\n",
        "\n",
        "def extract_dimencions(input_text):\n",
        "    words = nltk.word_tokenize(input_text)\n",
        "    dimencion_mapping = {\n",
        "        \"achievementId\",\n",
        "        \"adFormat\",\n",
        "        \"adSourceName\",\n",
        "        \"adUnitName\",\n",
        "        \"browser\"\n",
        "    }\n",
        "    for word in words:\n",
        "      if word in dimencion_mapping:\n",
        "        my_dimencion=word\n",
        "    return my_dimencion\n",
        "\n",
        "\n",
        "#DateRange(start_date=\"2024-02-01\", end_date=\"2024-03-01\")\n",
        "def run_report(property_id,matrics,extracted_matrixs):\n",
        "    \"\"\"        Runs a report by the client call       \"\"\"\n",
        "    client = BetaAnalyticsDataClient()\n",
        "\n",
        "    request = RunReportRequest(\n",
        "        property=f\"properties/{property_id}\",\n",
        "        dimensions=[Dimension(name=extracted_matrixs)],\n",
        "        metrics=[Metric(name=matrics)],\n",
        "        date_ranges=[DateRange(start_date=\"yesterday\",end_date=\"today\")],\n",
        "    )\n",
        "\n",
        "    response = client.run_report(request)\n",
        "    print_run_report_response(response)\n",
        "    print(response)\n",
        "\n",
        "\n",
        "def print_run_report_response(response):\n",
        "    #Prints results of a runReport call.\n",
        "    print(f\"{response.row_count} analytics rows found\")\n",
        "    for dimensionHeader in response.dimension_headers:\n",
        "        print(f\"Dimension header name: {dimensionHeader.name}\")\n",
        "\n",
        "    for metricHeader in response.metric_headers:\n",
        "        metric_type = MetricType(metricHeader.type_).name\n",
        "        print(f\"Metric header name: {metricHeader.name} ({metric_type})\")\n",
        "\n",
        "\n",
        "\n",
        "    print(\"Report result:\")\n",
        "    for rowIdx, row in enumerate(response.rows):\n",
        "        print(f\"\\nRow {rowIdx}\")\n",
        "        for i, dimension_value in enumerate(row.dimension_values):\n",
        "            dimension_name = response.dimension_headers[i].name\n",
        "            print(f\"{dimension_name}: {dimension_value.value}\")\n",
        "\n",
        "        for i, metric_value in enumerate(row.metric_values):\n",
        "            metric_name = response.metric_headers[i].name\n",
        "            print(f\"{metric_name}: {metric_value.value}\")\n",
        "   # return response\n",
        "   # format_report(request)\n",
        "\n",
        "\n",
        "#429150627\n",
        "#sessionstotalUsers\n",
        "if __name__== \"__main__\":\n",
        "\n",
        "  \"\"\"poperty=input(\"enter your poperty number         \")\"\"\"\n",
        "  X=input(\"enter your quieres     (u need to inter the matrix right)   \")\n",
        "  extracted_dimintion=extract_dimencions(X)\n",
        "  extracted_matrixs=extract_metrics(X)\n",
        "  data=run_report(429150627,extracted_matrixs,extracted_dimintion)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"json_object = json.dumps(data, indent=4)\n",
        "\n",
        "# Writing to sample.json\n",
        "with open(\"sample.json\", \"w\") as outfile:\n",
        "\toutfile.write(data)\"\"\"\n",
        "\n",
        "\n",
        "#\"\"\"fitch the totalUsers and the browser\n",
        "#  output_df=run_report(429150627,extracted_matrixs,extracted_dimintion)\n",
        "  #output_df.reset_index().to_excel('GA4_python_output.xlsx', sheet_name = 'GA4_report', engine = 'xlsxwriter')\n",
        "#  output_df.to_csv('GA4_python_output.csv')\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "O1QyeXFVp5I8"
      }
    }
  ]
}